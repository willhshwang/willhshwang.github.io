<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Will Hwang</title>

    <meta name="author" content="Will Hwang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Will Hwang
                </p>
                <p>
    Hi! I'm a Ph.D. candidate in Computer Science at Princeton University, where I am advised by Prof. Olga Russakovsky.
    My research interest lies in multimodal learning, particularly in the intersection of computer vision and natural language processing. 
    I am currently working on applying reinforcement learning to improve reasoning capabilities of Multimodal LLMs.  
		I received my BS and MS at the University of Chicago. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:hee.h@princeton.edu">Email</a> &nbsp;/&nbsp;
                  <a href="mailto:hee.h@princeton.edu">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=EUO6RMgAAAAJ&hl=en&oi=ao">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/will_hs_hwang">Twitter</a> &nbsp;/&nbsp;
                  <a href="www.linkedin.com/in/willhshwang">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/willh.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/willh.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Activities</h2>
                <ul style="list-style:none;padding-left:0;">
                  <li style="margin-bottom:8px;"><strong>10-2025:</strong>&nbsp;&nbsp;Our work on NRIP1 R448G has been accepted to <a href="https://www.pnas.org/">PNAS</a>.</li>
                  <li style="margin-bottom:8px;"><strong>08-2025:</strong>&nbsp;&nbsp;I will be serving as an instructor for  <a href="https://ai4all.princeton.edu/">Princeton AI4ALL</a></li>
                  <li style="margin-bottom:8px;"><strong>06-2025:</strong>&nbsp;&nbsp;We are excited to present COMPACT at various workshops at <a href="https://cvpr.thecvf.com/Conferences/2025">CVPR 2025</a>!</li>
                  <li style="margin-bottom:8px;"><strong>04-2025:</strong>&nbsp;&nbsp;COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning is posted on <a href="https://arxiv.org/abs/2504.21850">arXiv</a>.</li>
                  <li style="margin-bottom:8px;"><strong>04-2025:</strong>&nbsp;&nbsp;Learning a Doubly-Exponential Number of Concepts From Few Examples is accepted to <a href="https://cogsci.org/2025/">CogSci 2025</a>.</li>
                  <li style="margin-bottom:8px;"><strong>08-2024:</strong>&nbsp;&nbsp;Starting my Ph.D at Princeton!</li>
                  <li style="margin-bottom:8px;"><strong>10-2023:</strong>&nbsp;&nbsp;Our work on FinnGen single-cell multiome and immunophenotyping has been presented at <a href="https://www.ashg.org/wp-content/uploads/2023/10/ASHG2023-PosterAbstracts.pdf">ASHG 2023</a>.</li>
                  <li style="margin-bottom:8px;"><strong>07-2022:</strong>&nbsp;&nbsp;Starting as a Computational Associate at the Broad Institute of MIT and Harvard.</li>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/compact.png" alt="compact" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2504.21850">
                  <span class="papertitle">COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning</span>
                </a>
                <br>
                Xindi Wu*, <strong>Hee Seung Hwang*</strong>, Polina Kirichenko, Olga Russakovsky 
                <br>
                <em>preprint</em>
                <p>We present a compositional, complexity-aware VIT data recipe to improve visual reasoning in MLLMs.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/doubly.png" alt="doubly" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://osf.io/preprints/psyarxiv/vtyxj_v1">
                  <span class="papertitle">Learning a Doubly-Exponential Number of Concepts From Few Examples</span>
                </a>
                <br>
                Ilia Sucholutsky, Bonan Zhao, <strong>Hee Seung Hwang</strong>, Allison Chen, Olga Russakovsky, Tom Griffiths
                <br>
                <em>CogSci</em>, 2025
                <p>We present a novel minimal paradigm that explores how efficiently people can simultaneously learn visual and symbolic concepts.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/pnas.png" alt="pnas" width="160" height="160">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                  <span class="papertitle">Nuclear receptor coregulator NRIP1 R448G modulates T cell gut homing to control intestinal inflammation</span>
                </a>
                <br>
                Xiangjun Chen, <strong>Hee Seung Hwang</strong>, Bihua Li, Yanhua Zhao, Koushik Ghosh, Lei Deng, Elizabeth A. Creasey, Orr Ashenberg, Daniel B. Graham, Ramnik J. Xavier
                <br>
                <em>PNAS</em>, 122, 2025
                <p>We show that NRIP1 R448G leads to intestinal inflammation by activating T cell gut homing and inflammatory cytokine production.</p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>
                <ul style="list-style:none;padding-left:0;">
                  <li style="margin-bottom:8px;"><strong>AI4ALL Instructor:</strong>&nbsp;&nbsp;Princeton University, July 2025</li>
                  <li style="margin-bottom:8px;"><strong>Teaching Assistant:</strong>&nbsp;&nbsp;Computer Vision (CS429), Fall 2025</li>
                  <li style="margin-bottom:8px;"><strong>Mentorship:</strong>&nbsp;&nbsp;I am continuing to mentor students I've met along the way. Feel free to reach out!</li>
              </td>
            </tr>
          </tbody></table>
        
        <!-- Credit -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Credit: <a href="https://github.com/jonbarron/jonbarron_website">Jon Baron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>